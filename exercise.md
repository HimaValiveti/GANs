# Image Generation using GANs
## Learning Outcomes

* Understanding the basic components in Generative Adversarial Networks and their working principles
* Diving into the process of Image Generation with GANs
* Implementing GAN architectures using tensor flow and keras libraries
* Elaborate on the importance of activation functions 
* Addressing the challenges and Ethical and Societal concerns offered by the GAN architectures
* Evaluate and strategically choose GAN models applicable for diverse real-world scenarios


Generative Adversarial Networks (GANs) are a type of artificial intelligence model, developed by pairing opposing neural networks that can extract and represent complex features of images. 
Generator and the discriminator are the opposing networks here, where adversarial training is the vital principle in generation of counterfeit images. GANs employ an unsupervised learning setup with a loss function in the form of the discriminator's feedback. This allows the generator to generate realistic images without requiring explicitly labeled data; nonetheless GANs cannot be categorized as unsupervised learning, as the discriminator acts as a supervisor by continuously providing feedback to the generator, guiding it to craft images that resemble the original.
<center>
<img src="https://github.com/HimaValiveti/images/blob/main/Image1.JPG" width="500" height="300"> </center>

## Diving into the process of Image Generation with GANs

### Generator:

* The generator is a Convolutional Neural Network (CNN) sculpted to generate artificial audio, image and video samples that are in differentiable from the original samples. 

* A random noise vector (often distributed as Uniform or Gaussian) is given as input to the generator that manifests into mimic of the original image post several layers of computation. 

## Discriminator

* The discriminator determines the authentication of the image generated by the generator. 
* It analyses both the original (from training data) and counterfeit image (received from generator) and calculates the gradient (loss) and directs it to the generator for further training.
* The discriminator's output, often referred to as the "predicted label", signifies its probability assessment of whether an input image is original or fake. Predicted label is a continuous value ranging between 0 and 1. A value around 1, indicates the input image is highly likely to be real and fake if the label is closer to 0.

## Learning

* The gradient signal information is back propagated to the generator which helps it adjust its hyperparameters (learning rate, weights, bias, activation functions, loss function etc.) in the direction of minimizing the error, eventually realizing the original. 
* This iterative adversarial training procedure updates the weights and biases of both the networks and substantially enhances the network. 
* The generator masters in deception and the discriminator in identifying the counterfeit image.

## Implementation of GANs

Basic libraries used for generating GAN architecture in python are tensor flow and keras. A simple adversarial generator and discriminator model architecture is explored.

<center><img src="https://github.com/HimaValiveti/images/blob/main/code_libraries.jpg" width="400" height="50"> </center>

The generator consists of three dense layers wherein the output dense layer has the activation function ‘tanh’ which produces 28*28 (784) dimensional vector for every image input within a normalized range of [-1,1].  This vector is forwarded to the discriminator which flattens the 28*28 vector. The activation functions, Rectifier Linear Unit (ReLU) is used for faster convergence of the generator/ discriminator models and Sigmoid is used for depicting the originality of the image.

<center><img src="https://github.com/HimaValiveti/images/blob/main/discriptive_Model.jpg" width="400" height="200"> </center>

<center><img src="https://github.com/HimaValiveti/images/blob/main/generative_model_1.jpg" width="500" height="300"> </center>

Furthermore, the discriminator and generator are paired and adversarial training of both the models is implemented and the hyperparameters are updated according to the learning environment.

## The most prominent limitations of GANs,
 
**Mode collapse:** Generator fails to completely learn the distribution of the sample data and generates samples that lack diversity- Generator overfitting

**Vanishing Gradient:** Occurs when almost negligible gradient is back propagated by the discriminator to the generator hampering the updation of hyperparameters, slowing down the learning process- Discriminator overfitting


### Ethical Concerns
* The Deepfake video and audio of people is predominantly used in the entertainment industry but has witnessed alarming concerns that can cause fraud and harm on a global scale
* GANs have been widely used for mimicking the literature developed by humans indirectly violating the Intellectual Property Rights (IPR)
* The generated output can be prejudiced if the training data is not sensitized

## GAN models and applications

|Model | Prominent Features     | Applications       |
|---- | ------------ | ------------|
|Vanilla GAN **(2014)**	|Simple GAN with generator and discriminator pairing	|Image generation|
|Conditional GAN **(2015)**	|Labels and Texts appended for guided generation of images	| <li> Image Translation</li> <li>Text to Image tasks</li> |
|Deep Convolutional GANs **(2015)**	|Exploits the core principles of CNN	| <li> Landscape</li> <li>Monet</li> <li> Facial generation</li>|
|Wasserstein GANs **(2017)**	|Loss function is tabulated based on Wasserstein distance to enhance the stability of the duo	|Generating complex images|
|Style Transfer GANs **(2015)**	|Pre trained models are used  for feature extraction from images	|<li>Image manipulation </li><li>Artistic exploration </li>|
|Progressive GANs **(2018)**	|Start with images having low resolution during training, upsampling (generator) and downsampling (discrimator), Better stability|High resolution artistry|
|StyleGAN **(2019)**	|ProGAN	|Realistic and Diverse Facial generation|
|BigGAN **(2019)**		|ProGAN	|Large scale Image generation|
|Diffusion Models **(2020)**	|non-GAN model	|Text-to-image generation, image editing and manipulation|


## Conclusion

Over the past decade GAN models have been constantly evolving making them suitable for a plethora of computing applications. Higher quality of the training data and learning the model for a longer duration ensure that the generated data outperforms the original. Furthermore, imposing ethical guidelines and eliminating sensitive data can help mitigate the ethical concerns to a major extent.

## References

1. Porkodi, S. P., Sarada, V., Maik, V., & Gurushankar, K. (2023). Generic image application using GANs (generative adversarial networks): a review. Evolving Systems, 14(5), 903-917. 
2. Dash, A., Ye, J., & Wang, G. (2023). A review of Generative Adversarial Networks (GANs) and its applications in a wide variety of disciplines: From Medical to Remote Sensing. IEEE Access.
3. Saxena, D., & Cao, J. (2021). Generative adversarial networks (GANs) challenges, solutions, and future directions. ACM Computing Surveys (CSUR), 54(3), 1-42.
4. Sun, Y., Wu, Z., Ma, Y., & Tresp, V. (2024). Quantum Architecture Search with Unsupervised Representation Learning. arXiv preprint arXiv:2401.11576.

## Reflections

1. GAN is unsupervised learning model and explicitly differentiating it with supervised models would help the learner understand labelled and unlabelled data. I wanted to start by differentiating the descriptive and generative models but thought that I would be digressing away from the main topic of interest.
2. GANs are implemented on the principles of Deep neural networks where higher level of abstraction is plausible. I wasn’t sure if GANs can think exactly like humans and hence removed this statement.
3. Inspite of the underlying limitations related to Ethical usage and balancing the Generator and Discriminator, GANs are used for a multitude of applications statement has been removed.
4. Focus on architectures (U-Net) used in GANs would have made the reader understand the advancements in improved learning rate and faster convergence.
5. Sustainability of GANs  
